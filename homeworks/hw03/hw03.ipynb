{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 Supplemental Notebook\n",
    "\n",
    "## DSC 40A, Fall 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 â€“ Least Absolute Deviation Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we've implemented least squares regression, which you will need later on when drawing your graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares_regression(x, y):\n",
    "    \"\"\" Return the intercept and slope (w0, w1) of the least squares regression line for the input data. \"\"\"\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    r = np.corrcoef(x, y)[0, 1]\n",
    "    \n",
    "    w1 = r * np.std(y) / np.std(x)\n",
    "    w0 = np.mean(y) - w1 * np.mean(x)\n",
    "    \n",
    "    return (w0, w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read in the data we'll be working with and use the function above to find the slope and intercept of the least squares regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt(\"data/hw3data.csv\", delimiter=\",\") # Import the data\n",
    "\n",
    "def separate_data(data):\n",
    "    '''Separate an nx2 array of data into an x array and a y array.'''\n",
    "    x_values = data[:, 0]\n",
    "    y_values = data[:, 1]\n",
    "    return x_values, y_values\n",
    "\n",
    "x_values, y_values = separate_data(data)\n",
    "\n",
    "print(r\"The (w_0^*, w_1^*) pair for the least squares regression line is:\", least_squares_regression(x_values, y_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Part B: Least Absolute Deviation Regression </h3>\n",
    "\n",
    "For this part, you will need to implement two functions. \n",
    "\n",
    "The first function will calculate the mean absolute error for a given $(w_0, w_1)$ pair. This function will take in the values of $w_0$ and $w_1$ as well as the data in the form of a list of tuples and will return a float value corresponding to the mean absolute error, defined as $$R_{abs}(w_0, w_1) = \\frac{1}{n} \\displaystyle\\sum_{i=1}^{n} \\big|y_i - (w_0 + w_1x_i)\\big|$$\n",
    "\n",
    "The second function will go through all the lines that are generated and pick the one with the lowest mean absolute error. This function will take in a list of $(w_0, w_1)$ pairs, each represented as a tuple, and the data in the same format as the previous function. It should return the $(w_0, w_1)$ pair with the lowest mean absolute error. If multiple $(w_0, w_1)$ pairs have the same lowest mean absolute error, you can select any one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(w0, w1, data):\n",
    "    \"\"\" Return the mean absolute error evaluated at (w0, w1) for the given data.\n",
    "        Hint: You can do this with a for loop, or you can do this using np.abs and np.mean.\n",
    "    \"\"\"\n",
    "    x_values, y_values = separate_data(data)\n",
    "    return ... # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_line(lines, data):\n",
    "    \"\"\" Return the (w0, w1) pair from the list of lines that has the lowest mean absolute error.\n",
    "        Hint: The structure of this function is not that different than the structure of the function\n",
    "              you wrote in Homework 2, Problem 4e.\n",
    "    \"\"\"\n",
    "    best_line = ... # TODO\n",
    "    best_mae = np.inf\n",
    "    for ...: # TODO\n",
    "        mae = ... # TODO\n",
    "        if mae < best_mae:\n",
    "            best_line = ... # TODO\n",
    "            best_mae = ...  # TODO\n",
    "    return ... # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are being provided for you and they will generate all unique pairs of points from the data and all the lines from those pairs. You don't need to understand the first function, `generate_all_unique_pairs`, but you should understand the second function, `generate_all_lines`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_unique_pairs(data):\n",
    "    \"\"\" Generate a list of all possible pairs of points from the data. \"\"\"\n",
    "    return list(combinations(data, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_lines(pairs_of_points):\n",
    "    \"\"\" Generate each (w0, w1) pair for the line that goes through each given pair of points.\n",
    "        Uses the fact that there is a unique line that passes through any two points.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "\n",
    "    for pair in pairs_of_points:\n",
    "        point_1, point_2 = pair\n",
    "        slope = (point_2[1] - point_1[1]) / (point_2[0] - point_1[0])\n",
    "        intercept = point_1[1] - slope * point_1[0]\n",
    "        lines.append((intercept, slope))\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our procedure for generating the optimal LAD regression line is implemented we can calculate the LAD regression line for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = generate_all_unique_pairs(data) # Generate all unique pairs of data points from data\n",
    "lines = generate_all_lines(pairs) # Generate all (w0, w1) pairs corresponding to each unique pair of data points \n",
    "\n",
    "print(\"The (w_0^*, w_1^*) pair for the LAD regression line is: \", find_best_line(lines, data)) # Calculate and print intercept and slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Plotting the result\n",
    "\n",
    "Now that we have calculated the least squares regression line and the least absolute deviation regression line for our data, let's try plotting them together to see the difference! Generate a scatterplot with the data in black, the least squares line in blue, and the LAD line red. \n",
    "\n",
    "Below is some code to get you started. Make use of the functions you have written above to find the slopes and intercepts of the blue and red lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0_abs, w1_abs = ... # TODO (Hint: The answer can be found by piecing together the code in the previous code cell)\n",
    "w0_sq, w1_sq = ... # TODO\n",
    "\n",
    "# Add your code to generate the plot here\n",
    "plt.figure(figsize=(10, 5)) # Don't change this\n",
    "plt.plot(..., ..., color=\"blue\", label=\"Least Squares Line\") # TODO\n",
    "plt.plot(..., ..., color=\"red\", label=\"LAD Line\") # TODO\n",
    "plt.scatter(..., ..., color=\"black\") # TODO\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
