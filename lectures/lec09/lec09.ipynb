{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 9 – Multiple Linear Regression and Feature Engineering\n",
    "\n",
    "## DSC 40A, Fall 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1 – Multiple Linear Regression\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a data set of sales figures from different stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sales.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using just one feature\n",
    "\n",
    "Before we perform multiple linear regression, let's first just perform simple linear regression. We'll try and use square footage to predict net sales; our prediction rule will be\n",
    "\n",
    "$$\n",
    "\\text{predicted net sales} = w_0 + w_1 (\\text{square feet})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(data, x='sq_ft', y='net_sales', title='Net Sales vs. Square Feet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like $w_1^*$, the optimal slope, should be positive. To find $w_0^*$ and $w_1^*$, we'll solve the normal equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_normal_equations(X, y):\n",
    "    '''Returns the optimal parameter vector, w*, given a design matrix X and observation vector y.'''\n",
    "    return np.linalg.solve(X.T @ X, X.T @ y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['1'] = 1\n",
    "\n",
    "X_one_feature_model = data[['1', 'sq_ft']]\n",
    "X_one_feature_model.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['net_sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_one_feature_model = solve_normal_equations(X_one_feature_model, y)\n",
    "w_one_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is telling us that the best-fitting line to this dataset is\n",
    "\n",
    "$$\\text{predicted net sales} = 2.577 + 85.389 (\\text{square feet})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get predictions for all observations in my dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_one_feature_model @ w_one_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's draw a plot of our prediction rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(data, x='sq_ft', y='net_sales', title='Net Sales vs. Square Feet')\n",
    "\n",
    "x_range = np.linspace(0, 10)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x = data['sq_ft'], y = y, mode = 'markers', name = 'actual'))\n",
    "fig.add_trace(go.Scatter(x = x_range, \n",
    "                         y = w_one_feature_model[0] + w_one_feature_model[1] * x_range, \n",
    "                         name = 'linear prediction rule', \n",
    "                         line=dict(color='red')))\n",
    "\n",
    "fig.update_layout(xaxis_title = 'Square Feet', yaxis_title = 'Net Sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also worth calculating the mean squared error of this prediction rule, so that we can compare it to our later prediction rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(X, y, w):\n",
    "    return np.mean(np.sum((y - X @ w)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using two features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to predict net sales from two variables: the square footage (size) of the store, and the number of competing stores in the area. Our model will be:\n",
    "\n",
    "$$\n",
    "\\text{predicted net sales} = w_0 + w_1 (\\text{square feet}) + w_2(\\text{competitors})\n",
    "$$\n",
    "\n",
    "Suppose $w_0^*$, $w_1^*$, and $w_2^*$ are our prediction rule's optimal parameters. Do you expect $w_1^*$ to be positive or negative? What about $w_2^*$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(data, x='sq_ft', y='net_sales', title='Net Sales vs. Square Feet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(data, x='competing_stores', y='net_sales', title='Net Sales vs. Competing Stores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at separate scatter plots only tells part of the story. Let's look at a 3D scatter plot, with one axis for square footage, one axis for competing stores, and one axis for net sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter3d(x=data['sq_ft'], \n",
    "                           y=data['competing_stores'], \n",
    "                           z=data['net_sales'], mode='markers'))\n",
    "\n",
    "fig.update_layout(scene = dict(\n",
    "    xaxis_title = 'Square Feet',\n",
    "    yaxis_title = 'Competing Stores',\n",
    "    zaxis_title = 'Net Sales'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to find the best fitting **plane** to this set of points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion Question\n",
    "\n",
    "At the start of this notebook, we fit a prediction rule with a single feature, square feet, and got that the weight of that feature was $w_1^* = 85.389$.\n",
    "\n",
    "We are about to fit a prediction rule with two features, square feet and competing stores.\n",
    "\n",
    "**Question:** Is the weight of the square feet feature, $w_1^*$, for this **new** prediction rule guaranteed to be equal to 85.389?\n",
    "\n",
    "A. Yes\n",
    "\n",
    "B. No\n",
    "\n",
    "### To answer, go to [menti.com](https://menti.com) and enter the code 5115 8817."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our design matrix is:\n",
    "    \n",
    "$$\n",
    "\\begin{pmatrix}\n",
    " 1 & s_1 & c_1\\\\\n",
    " 1 & s_2 & c_2\\\\\n",
    " \\vdots & \\vdots & \\vdots\\\\\n",
    " 1 & s_n & c_n\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "where $s_i$ is the size of the $i$th store, and $c_n$ is the number of competitors. In code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_two_feature_model = data[['1', 'sq_ft', 'competing_stores']].values\n",
    "X_two_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function `solve_normal_equations` that we already built:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_two_feature_model = solve_normal_equations(X_two_feature_model, y)\n",
    "w_two_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is telling us that the best-fitting plane to this dataset is\n",
    "\n",
    "$$\\text{predicted net sales} = 303.491 + 45.151 (\\text{square feet}) - 21.585 (\\text{competing stores})$$\n",
    "\n",
    "**Note that the weight of $\\text{square feet}$ in this prediction rule is different than the weight of $\\text{square feet}$ in the prediction rule that only had one feature!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX, YY = np.mgrid[1:10:2, 0:16:2]\n",
    "Z = w_two_feature_model[0] + w_two_feature_model[1] * XX + w_two_feature_model[2] * YY\n",
    "plane = go.Surface(x=XX, y=YY, z=Z)\n",
    "\n",
    "fig = go.Figure(data=[plane])\n",
    "fig.add_trace(go.Scatter3d(x=data['sq_ft'], \n",
    "                           y=data['competing_stores'], \n",
    "                           z=data['net_sales'], mode='markers', marker = {'color': '#656DF1'}))\n",
    "\n",
    "fig.update_layout(scene = dict(\n",
    "    xaxis_title = 'Square Feet',\n",
    "    yaxis_title = 'Competing Stores',\n",
    "    zaxis_title = 'Net Sales'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, let's calculate the MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(X_two_feature_model, y, w_two_feature_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is significantly lower than the MSE of the model with just one feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(X_one_feature_model, y, w_one_feature_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All features\n",
    "\n",
    "Let's fit a prediction rule using all of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = ['1', 'sq_ft', 'competing_stores', 'inventory', 'advertising', 'district_size']\n",
    "X_all_features = data[column_order].values\n",
    "X_all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_all_features = solve_normal_equations(X_all_features, y)\n",
    "w_all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feature in enumerate(column_order):\n",
    "    if feature == '1':\n",
    "        print(f'intercept:\\t{w_all_features[0]:0.3f}')\n",
    "    else:\n",
    "        print(f'{feature}:\\t{w_all_features[i]:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE of this model is even lower!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(X_all_features, y, w_all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I can't visualize this prediction rule, since I would need to be able to visualize in 6D, but I can still find this prediction rule's predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_features @ w_all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which feature is most \"important\"?\n",
    "\n",
    "We should standardize in order to account for the difference in units and scale between the features.\n",
    "\n",
    "**Question:** What would happen if I try to standardize the column of all 1s? 🧐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[column_order].iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_features = (features - features.mean(axis=0)) / features.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standardized = np.column_stack([\n",
    "    np.ones(data.shape[0]),\n",
    "    standardized_features\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_standardized = solve_normal_equations(X_standardized, y)\n",
    "w_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feature in enumerate(column_order):\n",
    "    if feature == '1':\n",
    "        print(f'intercept:\\t{w_standardized[0]:0.3f}')\n",
    "    else:\n",
    "        print(f'{feature}:\\t{w_standardized[i]:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The district size appears to have the largest effect on the net sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(X_standardized, y, w_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that standardizing has no impact on the actual predictions made by our prediction rule, and hence the MSE – it just makes the weights more interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Feature Engineering\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = sns.load_dataset('mpg').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(cars, x='horsepower', y='mpg', title='MPG vs. Horsepower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regular linear model here isn't great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['1'] = 1\n",
    "w_cars_one_feature = solve_normal_equations(cars[['1', 'horsepower']], cars['mpg'])\n",
    "w_cars_one_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(cars, x='horsepower', y='mpg', title='MPG vs. Horsepower')\n",
    "\n",
    "x_range = np.linspace(40, 220)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x = cars['horsepower'], y = cars['mpg'], mode = 'markers', name = 'actual'))\n",
    "fig.add_trace(go.Scatter(x = x_range, \n",
    "                         y = w_cars_one_feature[0] + w_cars_one_feature[1] * x_range, \n",
    "                         name = 'linear prediction rule', \n",
    "                         line=dict(color='red')))\n",
    "\n",
    "fig.update_layout(xaxis_title = 'Horsepower', yaxis_title = 'MPG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we add $\\text{horsepower}^2$ as a feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['horsepower^2'] = cars['horsepower']**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars[['1', 'horsepower', 'horsepower^2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_cars_squared = solve_normal_equations(cars[['1', 'horsepower', 'horsepower^2']], cars['mpg'])\n",
    "w_cars_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the resulting prediction rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(cars, x='horsepower', y='mpg', title='MPG vs. Horsepower')\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x = cars['horsepower'], y = cars['mpg'], mode = 'markers', name = 'actual'))\n",
    "fig.add_trace(go.Scatter(x = x_range, \n",
    "                         y = w_cars_one_feature[0] + w_cars_one_feature[1] * x_range, \n",
    "                         name = 'linear prediction rule', \n",
    "                         line=dict(color='red')))\n",
    "fig.add_trace(go.Scatter(x = np.linspace(40, 220), \n",
    "                         y = w_cars_squared[0] + w_cars_squared[1] * x_range + w_cars_squared[2] * x_range**2, \n",
    "                         name = 'quadratic prediction rule', \n",
    "                         line=dict(color='#F7CF5D', width=5)))\n",
    "\n",
    "fig.update_layout(xaxis_title = 'Horsepower', yaxis_title = 'MPG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this is **still** a linear prediction rule – it's just not linear in terms of horsepower. **It is linear in terms of the parameter vector, $\\vec{w}$, which means we can still use the normal equations to find $\\vec{w}^*$**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
