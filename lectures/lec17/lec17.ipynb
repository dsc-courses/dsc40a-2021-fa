{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d791945",
   "metadata": {},
   "source": [
    "# Lecture 17 â€“ More Naive Bayes\n",
    "\n",
    "## DSC 40A, Fall 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fa53b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba64273",
   "metadata": {},
   "source": [
    "In this notebook we'll look at how to se Naive Bayes to classify emails as spam or ham (not spam).\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "<img src='https://images2.minutemediacdn.com/image/upload/c_crop,h_1576,w_2800,x_0,y_52/v1554931909/shape/mentalfloss/20997-istock-471531747.jpg?itok=3s4MLcXA' width=400></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66822665",
   "metadata": {},
   "source": [
    "### The data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f37100",
   "metadata": {},
   "source": [
    "Let's load in a dataset of real spam and ham emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4534bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/spam_ham_dataset.csv').get(['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeec75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7848b6c2",
   "metadata": {},
   "source": [
    "Here's what an email in our DataFrame looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd618947",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.get('text').iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f74d77",
   "metadata": {},
   "source": [
    "Let's convert all emails to lower-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25880edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf7faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.get('text').iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa17a86",
   "metadata": {},
   "source": [
    "### Creating a design matrix\n",
    "\n",
    "Let's load in a dictionary of words that we can use to differentiate spam and ham emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794afb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['body', 'click', 'please', 'base64', '2002', 'html', 'subscribed',\n",
    "         'wrote', 'mortgage', 'align3dcenterfont', 'dear', 'br', 'width10img',\n",
    "         'divfont', 'im', 'receive', 'list', 'tags', 'web', 'base64', 'click',\n",
    "         'body', 'please', 'money', 'offer', 'receive', 'contact', 'free',\n",
    "         'tr', 'removed', 'remove', 'html', 'font', 'form',\n",
    "         'credit', 'business', 'div']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9243d0bd",
   "metadata": {},
   "source": [
    "Before we run Naive Bayes, we need to use the bag-of-words encoding to come up with features.\n",
    "\n",
    "For a single word, such as `'please'`, we can come up with a column of our design matrix as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695b4a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'].str.contains('please').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52668087",
   "metadata": {},
   "source": [
    "To do this for every single word, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b31eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(email):\n",
    "    '''Returns a Series containing the feature vector for a single email.'''\n",
    "    return pd.Series({word: int(word in email) for word in words})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e8ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix = data['text'].apply(featurize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3946f208",
   "metadata": {},
   "source": [
    "`design_matrix` now contains one row per email and one column per word in our dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb722c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554815e9",
   "metadata": {},
   "source": [
    "### Setting up the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b84f7",
   "metadata": {},
   "source": [
    "We're now ready to run the Naive Bayes algorithm. We could do this ourselves by hand, but we'll instead use the `CategoricalNB` object from `sklearn` that you'll also use in Homework 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b022123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987288f5",
   "metadata": {},
   "source": [
    "Let's create a `CategoricalNB` object. `alpha=1` enables smoothing as we've defined it in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d37525",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CategoricalNB(alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69c90bb",
   "metadata": {},
   "source": [
    "We now need to \"fit\" the model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dda92f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X=design_matrix, y=data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09457dcd",
   "metadata": {},
   "source": [
    "### Making predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360828d5",
   "metadata": {},
   "source": [
    "Now that we've \"fit\" the model, we can use it to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c5af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(email, prob=False):\n",
    "    '''Calls model.predict to determine the predicted class (spam or ham) for a single email.\n",
    "       If the optional argument prob=True is used, the probability of the prediction for the more likely class is printed.\n",
    "    '''\n",
    "    if prob:\n",
    "        probs = model.predict_proba(featurize(email).values.reshape(1, -1))\n",
    "        print(f'Probability: {np.round(max(probs[0]), 4) * 100}%')\n",
    "    return model.predict(featurize(email).values.reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a06eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction('''\n",
    "my name is king triton\n",
    "please click on this email to receive free credit cards for your new business\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e9324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction('''\n",
    "hey! i had a question on homework 8, part 1d in dsc 40a.\n",
    "''', prob=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3284c55",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "A metric that we often use when classifying is **accuracy**, which is defined as the fraction of data points that were classified correctly.\n",
    "\n",
    "As it turns out, `sklearn` has a built-in method that calculates accuracy â€“ `.score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d507ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X=design_matrix, y=data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050a119a",
   "metadata": {},
   "source": [
    "This is telling us that Naive Bayes has an accuracy of 78.34% on the data in `design_matrix`. In practice, however, we'll often care more about the accuracy of a classifer on what is called **test data**, which is data that we didn't use to train the model. (Recall from earlier in the quarter, the purpose of a prediction rule is to make predictions about data for which we don't already know the \"right answer\".)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e72580",
   "metadata": {},
   "source": [
    "### More models\n",
    "\n",
    "As you know, DSC 40A is called **Theoretical Foundations of Data Science (Part 1)**. That's why we spent most of our time working on paper and talking about the math behind various techniques.\n",
    "\n",
    "To wrap up the quarter, we'll show you how we can classify emails as spam or ham using a variety of other models in `sklearn`, without walking through the math. You'll see the math in future courses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f8e971",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36125b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4126cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X=design_matrix, y=data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ced3e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.score(X=design_matrix, y=data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b094bd",
   "metadata": {},
   "source": [
    "Let's store our accuracies in a dictionary that we can refer back to later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8269881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accs = {}\n",
    "model_accs['naive bayes'] = model.score(X=design_matrix, y=data['label'])\n",
    "model_accs['logistic regression'] = lr_model.score(X=design_matrix, y=data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a1101a",
   "metadata": {},
   "source": [
    "**Decision Trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c95379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8d2a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X=design_matrix, y=data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b6f10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accs['decision tree'] = dt_model.score(X=design_matrix, y=data['label'])\n",
    "model_accs['decision tree']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c70638",
   "metadata": {},
   "source": [
    "**Support Vector Machines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd120d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bab1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC()\n",
    "svm_model.fit(X=design_matrix, y=data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f54f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accs['support vector machine'] = svm_model.score(X=design_matrix, y=data['label'])\n",
    "model_accs['support vector machine']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a3015b",
   "metadata": {},
   "source": [
    "**Overall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a285bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154eefe0",
   "metadata": {},
   "source": [
    "Note that the code for all three of these new models (Logistic Regression, Decision Trees, and Support Vector Machines) is almost identical. Under the hood, though, there's a lot of math going on. You now have a taste of the math that's involved in making predictions! ðŸ˜‡"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
